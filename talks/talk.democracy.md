---
theme: apple-basic
highlighter: prism
lineNumbers: false
drawings:
  persist: false
layout: cover
---

# Democracy doesn't have to suck

## we can make it excellent using Persistent Democracy

---

<v-clicks>

- problems caused by bad systems, not irrational people
- we can fix the problems!
  - score voting systems solve toxic polarization
  - resource voting systems solve vote spam
  - Persistent Voting solves deadline problems
  - concrete example
- true democracy and expert delegation are compatible
- true democracy is a moral imperative

</v-clicks>

---

bunch of problems

https://forum.effectivealtruism.org/posts/ax8fod4R7ihTxh3kv/persistent-democracy-request-for-early-feedback?commentId=jFQGHNrAHtb9zAcrZ

https://www.amazon.com/10-Less-Democracy-Should-Elites/dp/1503603571
better off according to whose measurements?
https://www.politico.com/news/magazine/2019/11/29/penn-station-robert-caro-073564
delegation isn't the problem, it's when that delegation isn't given in a democratically legitimate way
https://www.amazon.com/Why-Its-OK-Ignore-Politics/dp/1138389005
yeah people shouldn't vote on things *they don't know or care about*, but they should *be able to*
https://www.slowboring.com/p/the-rise-and-importance-of-secret
toxic polarization is much likelier a *symptom* of bad systems not the *cause*. it isn't an immutable fact

in an irrational environment, irrational behavior is rational
if the entire political landscape is toxically polarized and all power is assigned in the two party war, you *have* to fight the party war, otherwise you have no voice at all

a lot of these make a strawman assumption: that "democracy" means everyone personally signs off on every decision. that's not what it means
democracy just means weighing each person's *input* the same. that *input* can take dramatically different shapes!

- tyranny of the majority
- lesser of two evils
- toxic polarized culture
- apathetic voters
- uninformed voters
- voter disenfranchisement
- misinformation
- election hangovers
- unaccountable officials
- NIMBY-ism

---

is sane democracy simply impossible?

do people just suck too much?

---

not *causes*

but *symptoms*

---

the real problem?

## poor voting methods

right now we achieve stability and fairness (kinda) with weird adhoc rules, deadlines, time limitations, "representativeness"
these things don't actually achieve stability and fairness, but they *feel* like they do
the concept of resource voting achieves that goal much more cleanly.

people aren't stupid
people just aren't experts on every topic
people know best what they want, and things like "revealed vs stated" preferences are just as easily explained by exploitative systems rather than irrationality

you can redesign the lunchroom such that people will have different behavior. you can think of this as technocratic "development expertise". but you can also remember that if the users of that lunchroom want to be healthier, and you present the initiative to redesign it in the hopes to help them be healthier, then if they're given time to think about it and let the slow aspirational part of their mind make the decision

if they *don't* want to be healthier, then there's probably something else going on you don't understand!
insisting the things *you* care about be optimized without any concern for what other people want is the peak of moral arrogance

talk about anti-politics machine examples
you can't just insist everyone get on board with your program to

this is all probably making me sound like a market-absolutist libertarian. that's not true! I do think the underlying *flavor* of reasoning is shared, but I'm willing to accept that markets *as we understand them* aren't actually welfare-optimal and could be improved in ways that would make them "feel" more socialist

---

we can use math and logic to build *provably* better voting methods

---

- political problems caused by bad systems, not immutable badness, and the ethical questions of listening to people and giving them input
- are structurally solvable
- persistent democracy solves them, with a big concrete example

---

first offender:

# Plurality Voting

---

# Plurality Voting is awful

---

democracy != plurality voting

---

approval voting is much better!

part of a general group of systems I'll call "score systems"

solves spoiler effect

(note, systems like ranked choice voting *don't*, that's a subject for a different talk)

---

not good enough

doesn't account for preference strength

allows vote spam

---

quadratic voting is better

part of a general group of systems I'll call "resource systems"

solves "vote spam"

would solve things like NIMBY-ism

---

not good enough

allows "savings strategies"

---

deadline problem
I want to convince you that a key of unraveling this question is to find a way to get rid of all unnecessary election deadlines

---

persistent voting

---

lots of slides discussing benefits and details
ask people to be patient as you go through these important details

---

briefly say you'll talk about persistent commitments in a second

---

persistent constitutions

---

extended example of a country that uses it, far in the future
first go through someone going to a voting office
starting with election for constitution
the constitution directly defines rights so they aren't different all over the place
it splits off documents for districts, rights clarifications, and agencies/officials
go through a process of different drafts adopting easy to agree on compromises and therefore getting stronger
then discuss bits of districts, agencies (does the county auditor actually need to be an elected position?)
discuss how stabilization buckets relate to depth in constitutional tree

---

lots of other stuff:

- common resource rights
- persistent funding
- intellectual property
- provably optimal?

---

plan to make it a reality










































We can only truly improve the world by improving Democracy. Charitable giving is nothing more than a stop-gap.

It is impossible to improve the state of the world without first fixing democratic systems, because all forms of aggregating utilitarianism are nonsensical.

This post is largely a response to this:
https://astralcodexten.substack.com/p/your-book-review-the-anti-politics
I agree with the thrust of the criticism, but think this doesn't go nearly far enough.

If I had to point my finger at the main philosophical mistake I believe EA makes, it's the general acceptance of some kind of "universal view" utilitarianism. I've been working on an alternate axiology, but I'll just do a bad job of explaining it here to stand as a contrast.

TODO

when we do direct cash transfers, we're basically just implementing a rough version of a continuous wealth tax. when we do various public good producing programs, we're *hopefully* building public goods people would build for themselves if they had the resources and coordination tools.

even improving science/meta-science naturally flows from improving democracy, since science can be a public good, and better democracies will better support and incentivize public goods.
charitable giving is just a not-as-good version of a continuous inequality-dynamic externality-based wealth tax (if no one in the world was severely cut off from modern technology and could at any time pursue education programs then maybe it would make sense to just spend your money on fancy homes and vacations)

there's the "type theory" version of the argument (that allowing comparison of distinct qualia/welfare types is undefined without an axiomatic assumption) and the more obvious humble version (you can't assume you know what's best for people, you have to not just ask them but truly give them full equal power/input)


It seems obvious to me that a future where quadrillions of beings are immensely wealthy and happy but some (even tiny!) number of beings don't have a full democratic voice that *could* is an unacceptable situation that would be better morally traded for a much less prosperous future where everyone *does* have full democratic voice
we use words like "slave" to indicate these situations to indicate the gap between possibility and reality. if a society has slaves then conscious decisions have been made to subjugate people, and it's clear different choices could be made immediately to improve subject-blindness.

if a society allows the possibility of someone mistakenly getting trapped on a desert island and therefore having no democratic voice, well that's almost uncertainly an unavoidable tragedy. no one *chose* to make it happen, and the fact it happened was *in spite* of proper democratic equality, and likely happened as a result of peoples' willing choices and risks. things like that likely happen strictly less than a world in which people *don't* have equal democratic voice, because they can be forced into situations they wouldn't choose themselves.

this is the crux: it doesn't matter if a society is massively wealthy and prosperous if they make choices that deprive people of democratic voice

if you asked me if I would choose to either inhabit a prosperous world created by *chosen* subject-aware suffering before my time or a much less prosperous world preceded by subject-blindness (or to not exist at all), I think it's my moral obligation to choose the subject-blind version.

My main critique here is that we *still* don't escape from the "development lens". Qualitiative research isn't good enough. Just "asking people" isn't good enough. Those people should *be in charge*, they should have equal democratic voice to push for the things they actually want. That won't magically fix everything, because even a community that fully knows what it wants will make flawed predictions about what will actually *achieve* what they want.
randomized controled trials are useful, but only if they're being conducted *by* the people they will effect (or at least under their supervision)

the problem is that we *also* can't just force democratic systems on people! it seems the best we can do is experiment with systems ourselves, and if they actually work better people will copy them. if we can't build systems that solve our *own* problems, we certainly can't systems that solve others'

this isn't to say we should never do aid work. we should, but only as a stop gap. it seems to me the only *real* solution to the problem of global inequality is a [global wealth tax](TODO). but it seems much more of our effort should be spent building flexible and dynamic systems that could theoretically be applied anywhere (and then test the bejesus out of them to see what our theory missed)

the most obvious criticism of this post is that it could benefit *me*, because I want to do work to build Persistent Democracy. I fully recognize that criticism! But honestly, if someone else just took up that program and completely ignored me I wouldn't mind that, as long as I thought their work/conclusions were good. I don't care! I have lots of other things I can work on. But I'm very convinced democracy is the thing that matters, and specifically Persistent Democracy has the best chance I can imagine to maximize its potential.

the goal of persistent democracy is to be a system that if used by *any* group of people in *any* environment/universe would lead to welfare-optimal cooperation. it's not an accident that the *core* constructs of persistent democracy are extremely minimal and unopinionated, and that they are broadly close to market structures (importantly, they're inspired by markets but aren't "true" markets as we typically understand them)

the only predictive model that can robustly have any predictive weight is one that directly incorporates the inputs of those effected. their models can be incorrect, but that's why we gather *all* their input so hopefully some error cancels out, and over time people can observe the difference between their predictions and reality. if you think you have the answer and can update their models, then that's why you can present your case to them and maybe persuade them, and if you're unable to persuade them it's more likely they have some contextual knowledge they haven't figured out how to share with you rather than they are simply *all* deceived.





Exploring function-comparing ethics vs person-comparing ethics

https://forum.effectivealtruism.org/posts/LPDyAvwYyp4tzPmED/common-sense-cases-where-hypothetical-future-people-matter

you can only help future people by building *general systems* that are structurally capable of helping anyone. "anyone" is allowed to be narrow if your system is very grounded in a specific context, but the system you build should probably therefore be highly adaptable so it can respond to changes in that context.
all of these cases rely on how you act *in relation to the state of the world*. stewardship of the *universe* and the structures that
the subject-blind function-oriented ethical frame preserves the *intuitive* motivations of longtermism without allowing the repugnant conclusions implied by *any* form of aggregating utilitarianism

if on the other hand you're trading between harming a person now to help a person later, the *real* reason you don't harm the person now is because that course of action preserves option value for you to do both not harm the person now *and* help the person later!
*harming* a person both now or in the future is also morally equivalent! however the *only* people you can concretely help or harm exist in the present, by definition at all timesteps. you can only act toward people in the future by effecting the *world* now. your actions should be evaluated by how they treat *everyone* in a subject-blind way.

https://forum.effectivealtruism.org/posts/HyeTgKBv7DjZYjcQT/the-problem-with-person-affecting-views
actions aren't good or bad for *anyone* until you've solicited the input of that someone!

you might *think* an action such as giving someone money will always be good for them but think about the case of "don't tempt me frodo". as difficult as it might be to imagine the possibility, someone might consider it *harmful* to even be *presented* with an offer of money.
or more grounded: a recovering drug addict who is in a program they chose that takes care of all their needs, but any "extra" money will merely tempt them to relapse.

the lexicographic ordering concept neatly sidesteps:
> Neutrality Principle: Adding an extra person to the world, if it is done in such a way as to leave the well-being levels of others unaffected, does not make a state of affairs either better or worse.

we *do* consider it better to create new beings, but only *after* present-being subject-blind democracy

**function-comparing ethics** is less assumptive than all forms of **person-comparing ethics** because function-comparing only compares beings to themselves, even better only compares *valuations* of beings from themselves

maybe: two functions with the same subject-blindness can be better if one of them encourages creating more people *unless creating those people would violate subject-blindness*. this is even stronger than


*linear* rankability isn't necessary to prioritize one thing over another, because lexicographic orderings can restrict themselves to only comparing like types *and* still prioritize some *types* over another.
but even then you can only linearly rank things in the same type

https://www.cold-takes.com/future-proof-ethics/


- type-theoretical rather than numerical models of beings (makes fewer assumptions)
- vectors of beings rather than mere "sums" across beings
- lexicographic orderings rather than mere linear orderings

> In theory, any harm can be outweighed by something that benefits a large enough number of persons, even if it benefits them in a minor way.

only if that person had equal weight to consider their output!

instead of weighing the *inherent* morality of giving a million people a bednet, we simply ask "do those million people *want* a bednet? how much compared to other things?"

you could spend a bunch of money giving people bednets. or you could donate that money to build a cooperative governed by the people for them to use to build whatever arbitrary public goods they value most.

https://forum.effectivealtruism.org/posts/iupkbiubpzDDGRpka/other-centered-ethics-and-harsanyi-s-aggregation-theorem
the snuck assumption in Harsanyi's Aggregation Theorem is that you can aggregate welfares of different people. you can aggregate their *solicited preferences*, but only through a voting system, so the only mechanism that could possibly *achieve* HAT is something like persistent democracy


with welfare types like these, how do we go about "adding" them together? the very act of adding them together assumes they have types for which an operation has been defined for them that has all the properties of addition (is abelian, etc)

```v
Inductive A :=
  | red
  | yellow
  | blue
.

Inductive B :=
  | mountain
  | forest
.
```

however it *is* reasonable to assume each being has an *internal* and *opaque* function they could use to assign value to different welfare outcomes at different timesteps.

the important thing is that we can recover all the reasonable and consistent conclusions of utilitarianism without the repugnant conclusions.

when comparing vectors we do this:

- align all beings with themselves. we can compare that being's valuation to itself, so we can say whether their valuation went up or down
- find all the beings that are added (born)
- find all the beings that are removed (die)

```v
Inductive Difference :=
  | DifferenceSelf (valuation_difference: integer)
  | DifferenceBirth (born_id: person_id)
  | DifferenceDeath (died_id: person_id)
.

Fixpoint ComputeDifference (A B: BeingsVector): Difference :=
  (* ... *)
.
```

we can see the last two things are entirely different types from the first. there isn't a non-axiomatic way we can compare a birth to a death to a change in welfare.

it could be reasonable in some situations to make more assumptions to have a "rough and ready" model for helping people. but that model must continue to respect subject-blindness to be consistent with this system.

https://www.cold-takes.com/defending-one-dimensional-ethics/
